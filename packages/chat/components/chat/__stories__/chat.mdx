import { Markdown, Meta, ArgTypes} from '@storybook/blocks';
import { cdnJs, cdnCss } from '../../../../../globals/internal/storybook-cdn';
import * as ChatStories from './chat.stories';
import packageJson from '../../../package.json';


<Meta of={ChatStories} />
# Chat Handbook

## Table of Contents

 - [Overview](#overview)
   - [Attributes and Properties](#attributes-and-properties)
   - [Events](#events)
   - [Troubleshooting](#troubleshooting)
 - [Installation](#installation)
   - [JS via import](#js-via-import)
 - [Implementation](#implementation)
   - [Preface](#preface)
   - [Basic implementation](#basic-implementation)
   - [Render with any API](#render-with-any-api)
   - [Render from Parent](#render-from-parent)
   - [Full Customization with Slotting](#full-customization-with-slotting)
 - [Styles](#styles)

## Overview 
<a id="overview"></a>

The Chat component is a collaboration between the **IBM Research Visual AI Lab (VAIL)** and the **Carbon Design Team** to provide an open-source, easily expandable chat interface to interact with large language models. Our core values are: open-source collaboration, universal support, ease of use and the in-depth customization Carbon is known for.

It is part of **Carbon Labs**, a test bed to let anyone experiment with novel LLM-enabled components. We chose LIT **web-components** as these can be used directly in **Vanilla**, **Svelte** and **React**. Our primary goal is to provide a space for novel and experimental features/components to be used in and out of Chat interfaces. By fully adhering to the latest design/safety/formatting guidelines, **Labs** can accelerate and streamline adoption across IBM to respond to the fast-moving field of AI and Large Language Models.

### Attributes and Properties 
<a id="attributes-and-properties"></a>

<ArgTypes story="Playground"/>

### Events 
<a id="events"></a>

<table>
  <thead>
    <tr>
        <td>**Event name**</td>
        <td>**Exclusive to chat mode**</td>
        <td>**Triggering logic**</td>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td>on-chat-slot-update</td>
        <td>Carbon slotting in use</td>
        <td>Return child update status</td>
    </tr>
    <tr>
        <td>on-user-regeneration-request</td>
        <td>API mode in use</td>
        <td>Return when user requested regeneration on any bot message</td>
    </tr>
    <tr>
        <td>on-chat-close</td>
        <td>All</td>
        <td>Return when user clicked close in the header</td>
    </tr>
    <tr>
        <td>on-user-message-update-request</td>
        <td>API mode in use</td>
        <td>Return when user requested an edit on any user message</td>
    </tr>
    <tr>
        <td>on-submit</td>
        <td>All</td>
        <td>Return when user submits a query in the footer</td>
    </tr>
  </tbody>
</table>

### Troubleshooting 
<a id="troubleshooting"></a> 

Contact **Owen Cornec** on Slack or at **o.cornec@ibm.com** for requests regarding general information, installation, trouble-shooting and custom features.


## Installation 
<a id="installation"></a>

Here's a quick example to get you started.

### JS via import 
<a id="js-via-import"></a>

```javascript
import '@carbon-labs/ai-chat/es/index.js';
```

## Implementation 
<a id="inplementation"></a>

### Preface 
<a id="preface"></a>

There are three ways to implement Chat: Add an API and directly auto-parse raw LLM responses, ingest your own conversation object from a parent application or specify every layer of the chat component and slot in custom components

#### 1: Auto-rendering with an API: specify a URL in the api-url attribute to query a proxy server

    - return a **reply string** containing raw LLM text: auto-rendering will parse and display subcomponents
    - return a **reply object** with a message JSON: items will be rendered as-is (see format below)
    - enable **stream-contents** : token streaming will be interpreted and automatically parsed then rendered

#### 2: API-less control with JSON object in **conversation** attribute:

    - All automatic behavior is disabled. You will be required to provide your own conversation object as well as handle all events such as users submitting/editing/regenerating messages, handling api responses outside the chat, enabling loading and handling feedback events
    - Create an array of messages with origin/timestamp/displayname, then in **elements** add objects containing **type** and **content**: **content** is a stringified object containing strings for plain text, URLs, arrays or a complex JSON objects. **type** denotes the component to be rendered in the message list such as **text**, **code**, **chart**, **image**, **table**, **carousel** etc

#### 3: Slotting: fully customize the chat by inserting custom divs and components:

    - Place all components directly in the chat tag and import any component you wish to use with the appropriate slot name
    - additionally, place custom div or external iframes/components directly into the message response
    - like section 2, all events must be handled by the parent application

### Basic implementation 
<a id="basic-implementation"></a>

```html
<clabs-chat
  <!-- string: user-name in LLM conversation -->
  user-name="user"
  <!-- string: agent name in LLM conversation -->
  agent-name="bot"
  <!-- (optional) string: api url to send user queries to -->
  api-url="localhost:5000/generate_response"
  <!-- (optional) boolean: whether to autoparse responses from LLM -->
  auto-update
  <!-- (optional) boolean: show loading state while model is thinking -->
  loading
  <!-- (optional) boolean: enable token streaming mode from specified api -->
  stream-content
  <!-- (optional) string: specify desired model -->
  model="llama-2"
  <!-- (optional) string: specify custom system prompt for LLM -->
  user-prompt="You are Watson, a helpful assistant"
  <!-- (optional) float: specify temperature for LLM responses -->
  temperature="0.15"
  >
</clabs-chat>
```

### 1: Auto-rendering with an API 
<a id="render-with-any-api"></a>

#### Basic usage

```html
<clabs-chat
  model="llama-2"
  user-prompt="You are Watson, a helpful assistant"
  api-url="localhost:5001/generate_response"
  temperature="0.15">
</clabs-chat>
```

All events/interactions are executed internally, any user query sent to the `api-url` and packaged as such:

```json
{
  "user_id": "xxxxxx",
  "session": "af90-dfgs-ek2a-vld9-wej",
  "event": 0,
  "prompt": "You are Watson, a helpful and polite assistant. You will answer all my questions to the best of your knowledge.",
  "context": "user:hi\nbot:hello how are you?",
  "entry": "I'm fine thank you",
  "temperature": 0.15,
  "max_tokens": 1000,
  "top_p": 0,
  "frequency_penalty": 1,
  "presence_penalty": 0,
  "n": 1,
  "user_name": "user",
  "agent_name": "bot",
  "max_tries": 3
}
```
#### Raw text response
If API returns raw LLM text in a `reply` of type `string`, auto-parsing will be used to slice/classify text into subcompoments within a message.

#### Object response
If API returns a `reply` of type `object/json`, objects are rendered as-is in order of appearance, each containing a subelement containing a`type` string which render a `content` field:

```json
[
  {"type": "text", "content": "Hello World!"},
  {"type": "html-text", "content": "<h2>Title</h2>"},
  {"type": "annotated-text", "content": "The link your requested is [here](http://www.google.com)"},
  {"type": "url", "content": "http://www.ibm.com"},
  {"type": "code", "content": "python\ndef Prime(number,itr):\n\t#base condition\n\tif ..."},
  {"type": "error", "content": "ERROR: API failed to respond, try again"},
  {"type": "image", "content": "http://www.gallery.come/image.png"},
  {"type": "video", "content": "http://www.wikimedia.org/example_video.mp4"},
  {"type": "file", "content": "ftp:spreadsheet.csv"},
  {"type": "carousel", "content": "['http://www.google.com', 'http://www.facebook.com', 'http://www.wikipedia.org']"},
  {"type": "table", "content": "header1,hedaer2,header3\n300,500,600\nNY,AK,MI"},
  {"type": "tags", "content": "['new chat','save chat','create chart']"},
  {"type": "chart", "content": "PLACE STRINGIFIED VEGA SCHEME HERE"}
]
```

#### Streaming option: response must be a string token and subcomponents will accept incomplete streamed text:

```html
<clabs-chat
  user-name="user"
  agent-name="bot"
  stream-responses
  api-url="localhost:5001/generate_response">
</clabs-chat>
```

### 2: API-less control with JSON object 
<a id="render-from-parent"></a>

#### Specifiy a **conversation** object and specify the loading state and every interaction outside the chat, then update the **conversation** object to see an update:

```html
<clabs-chat
  user-name="user"
  agent-name="bot"
  loading="{false}"
  .conversation="{conversationJSON}"
  @on-user-text-input="${(e) => {
    //user sent a message request through the text input footer
  }}"
  @on-user-message-update-request="${(e) => {
    //user edited a message in the chat
  }}"
  @on-user-regeneration-request="${(e) => {
    //user clicked 'regenerate' in a bot response
  }}"
  @on-user-feedback-request="${(e) => {
    //user clicked thumbs up or thumbs down on a bot response
  }}"
  @on-message-element-tag-selected="${(e) => {
    //user clicked a tag action element in the chat
  }}"
  @on-message-element-selected="${(e) => {
    //user clicked on a subelement in the chat
  }}">
</clabs-chat>
```

#### Conversation format:

```js
[
  {
    origin: 'bot',
    time: '4:51pm',
    disableButtons: true,
    displayName: "Watson",
    elements: [{ content: 'Hello friend', type: 'text' }] //message format
  },
  {
    origin: 'user',
    time: '4:56pm',
    displayName: "Owen",
    disableButtons: false,
    elements: [
      { content: 'Hello, how are you? I have a file to analyze:', type: 'text' },
      { content: 'ftp:spreadsheet.csv','file'}]  //message format
  },
  {
    origin: 'bot',
    time: '4:59pm',
    disableButtons: true,
    displayName: "Watson",
    elements: [
      { content: 'Here is your table:', type: 'text' },
      { content: 'age,name,state\n39,george,NY\n42,Mike,AK\n25,Linda,IL', type: 'table' }
      ]
  }
]
```

### Full Customization with Slotting 
<a id="full-customization-with-slotting"></a>

```html
 <clabs-chat user-name="user" agent-name="bot" conversation="{conversation}">
  <clabs-chat-messages slot="messages">

    <clabs-chat-message slot="message-items" origin="user" time-stamp="9:02pm" index="0">
      <clabs-chat-text slot="message-item-content" content="Showcase every type of Element available in this Chat component.">
      </clabs-chat-text>
    </clabs-chat-message>

    <clabs-chat-message slot="message-items" origin="bot" time-stamp="9:04pm" index="1">

      <!-- Display a text element -->
      <clabs-chat-text slot="message-item-content" content='This is a textElement, displays text following Carbon design guidelines.'></clabs-chat-text>

      <!-- Display a text element with HTML included -->
      <clabs-chat-text slot="message-item-content" content='TextElement can also render simple HTML as such:\n <h2>This is using a h2 tag</h2>\n'></clabs-chat-text>

      <!-- Custom slotted div with any content -->
      <div slot="message-item-content">
        <iframe width="256" height="256" src="https://www.youtube.com/embed/oSCX78-8-q0?si=kCcIHjehhVn-4PSO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      </div>

      <!-- File Card -->
      <clabs-chat-card slot="message-item-content" type="file" content='https://arxiv.org/pdf/2312.05688.pdf'></clabs-chat-card>

      <!-- Show a CSV table -->
      <clabs-chat-table slot="message-item-content" content='Name,Age,Occupation,Location,State\nJerry,35,Comedian,Upper east side,NY\nGeorge,35,Unemployed,Queens,NY\nElaine,32,Publisher,Midtown,NY\nKramer,36,Unknown,Upper east side,NY'></clabs-chat-table>

      <!-- Show code -->
      <clabs-chat-code slot="message-item-content" content='from math import sqrt\n#prime function to check given number prime or not:\ndef Prime(number,itr):\n\t#base condition\n\tif itr == 1:\n\t\treturn True\n\t#if given number divided by itr or not\n\tif number % itr == 0:\n\t\treturn False\n\t#Recursive function Call\n\tif Prime(number,itr-1) == False:\n\t\treturn False\n\treturn True\n'></clabs-chat-code>

      <!-- Action buttons -->
      <clabs-chat-tags slot="message-item-content" content='["Simone de Beauvoir","RenÃ© Descartes","Jean-Paul Sartre","Voltaire","Michel Foucault","Albert Camus"]'></<clabs-chat-tags>

      <!-- Text lists -->
      <clabs-chat-list slot="message-item-content" content='1. Google.com (United States)\n2. YouTube.com (US)\n3. Facebook.com (US)\n4. Baidu.com (China)\n5. Wikipedia.org (US)'></clabs-chat-list>

      <!-- Charts -->
      <clabs-chat-chart container-height="200px" slot="message-item-content" content='{"$schema":"https://vega.github.io/schema/vega-lite/v5.json","description":"Boxplot example with random data","data":{"values":[{"group":"Group A","value":34},{"group":"Group A","value":28},{"group":"Group A","value":55},{"group":"Group B","value":91},{"group":"Group B","value":81},{"group":"Group B","value":67}]},"mark":"boxplot","encoding":{"y":{"field":"group","type":"nominal"},"x":{"field":"value","type":"quantitative"}}}'></clabs-chat-chart>

    </clabs-chat-message>

  </clabs-chat-messages>

</clabs-chat>
```

### Styles

You'll also need to import the theming tokens from `@carbon/styles` either from
npm or from our CDN helpers. Checkout our Stackblitz example above to see how
that is implemented.

<Markdown>{`${cdnJs({ components: ['chat'] }, packageJson)}`}</Markdown>
<Markdown>{`${cdnCss()}`}</Markdown>
